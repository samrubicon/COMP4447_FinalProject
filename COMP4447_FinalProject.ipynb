{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bsoup\n",
    "import urllib.robotparser\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "import time\n",
    "import dateparser\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GeckoDriverManager module.\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "# Install the GeckoDriverManager to run FireFox web browser (for the first time!)\n",
    "# driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "\n",
    "# Once driver is installed, use this line:\n",
    "driver = webdriver.Firefox(executable_path='./geckodriver.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandcamp Web Scraper Data format information\n",
    "\n",
    "'''\n",
    "\n",
    "scrape_data = pd.DataFrame(columns=['Release Title', \n",
    "                                    'Artist Name', \n",
    "                                    'Artist Location',\n",
    "                                    'Release Date',\n",
    "                                    'Release URL',\n",
    "                                    'Release Genre',\n",
    "                                    'Release Sub-Genre',\n",
    "                                    'Search Format',\n",
    "                                    'Search Week',\n",
    "                                    'Search Category',\n",
    "                                    'All Lyrics',\n",
    "                                    'Number of Tracks'\n",
    "                                    'Track Info',\n",
    "                                    'Number of Fans',\n",
    "                                    'Tags',\n",
    "                                    'Scrape Date'])\n",
    "                                    \n",
    "### dictionary entry for track listing\n",
    "\n",
    "track_info_entry = {\n",
    "    'Track Title' : '',\n",
    "    'Track Lyrics' : '',\n",
    "    'Track Number' : '#',\n",
    "    'Track Duration': '##:##'\n",
    "}\n",
    "                                    \n",
    "'''\n",
    "\n",
    "# valid weeks: [-1,0,678,677,676,675,674,673]\n",
    "# today, this week, last week, 2, 3, 4, 5, 6 weeks ago\n",
    "WEEK_DICT = {\n",
    "    -1:'today',\n",
    "    0:'this week',\n",
    "    678:'last week',\n",
    "    677:'2 weeks ago',\n",
    "    676:'3 weeks ago',\n",
    "    675:'4 weeks ago',\n",
    "    674:'5 weeks ago',\n",
    "    673:'6 weeks ago'\n",
    "}\n",
    "\n",
    "# scrape dataframe list to collect release entries\n",
    "scrape_data = []\n",
    "\n",
    "# all URLS collected so far (don't collect duplicate albums for multiple searches)\n",
    "# load 'all_URLS_collected.txt' file if it exists\n",
    "all_URLS_collected = []\n",
    "URLS_file = Path(\"all_URLS_collected.txt\")\n",
    "if URLS_file.is_file():\n",
    "    with open(\"all_URLS_collected.txt\", \"r\") as fp:\n",
    "        all_URLS_collected = json.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape bandcamp release page function\n",
    "def scrape_release_page(URL,entry,output=False):\n",
    "    \n",
    "    entry = entry.copy()\n",
    "    \n",
    "    entry['Release URL'] = URL\n",
    "    entry['Scrape Date'] = datetime.datetime.now().date()\n",
    "    \n",
    "    # don't add entry if it already exists in scrape dataframe\n",
    "    if URL in all_URLS_collected:\n",
    "        return\n",
    "    else:\n",
    "        all_URLS_collected.append(URL)\n",
    "    \n",
    "    if output==True:\n",
    "        print('retrieving info for ' + URL + ' ...')\n",
    "\n",
    "    headers = {'user-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(URL,headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "\n",
    "        soup = bsoup(response.text, 'lxml')\n",
    "        \n",
    "        # Get title and artist name\n",
    "        title = soup.find('meta',{'name':'title'})['content'].split(', by ')\n",
    "        entry['Release Title'] = title[0]\n",
    "        entry['Artist Name'] = title[1]\n",
    "        \n",
    "        # Get artist location\n",
    "        entry['Artist Location'] = soup.find('span',{'class':'location secondaryText'}).string\n",
    "        \n",
    "        # Get release date\n",
    "        release_date = soup.find('div',{'class':'tralbumData tralbum-credits'}).contents[0].string.strip('\"').strip(' ').replace('releases','').replace('released','')\n",
    "        release_date = dateparser.parse(release_date)\n",
    "        entry['Release Date'] = release_date\n",
    "        \n",
    "        # Get tags\n",
    "        tags = soup.find_all('a',{'class':'tag'})\n",
    "        tags_list = []\n",
    "        for tag in tags:\n",
    "            tags_list.append(tag.string)\n",
    "        entry['Tags'] = tags_list\n",
    "        \n",
    "        # If no genre in entry, leave blank\n",
    "        if 'Release Genre' not in entry:\n",
    "            entry['Release Genre'] = 'N/A'\n",
    "            \n",
    "        # If no subgenre in entry, leave blank\n",
    "        if 'Release Sub-Genre' not in entry:\n",
    "            entry['Release Sub-Genre'] = 'N/A'            \n",
    "        \n",
    "        # Get track information\n",
    "        entry['Track Info'] = []\n",
    "        #tracks = soup.find('table',{'id':'track_table'}).findChildren('tr', recursive=False)\n",
    "        tracks = soup.find('table',{'id':'track_table'}).find_all('tr',{'class':'track_row_view'})\n",
    "        \n",
    "        all_lyrics = ''\n",
    "        for track in tracks:\n",
    "            # Track number\n",
    "            track_num = int(track.find('td',{'class':'track-number-col'}).div.string.strip('.'))\n",
    "\n",
    "            # Track title\n",
    "            track_title = track.find('span',{'class':'track-title'})\n",
    "            if track_title:\n",
    "                track_title = track_title.string\n",
    "            else:\n",
    "                track_title = track.find('div',{'class':'title'}).span.string\n",
    "        \n",
    "            # Track duration\n",
    "            track_duration = track.find('span',{'class':'time secondaryText'})\n",
    "            if track_duration:\n",
    "                track_duration = track_duration.string.replace('\\n','').strip(' ')\n",
    "            else:\n",
    "                track_duration = 'N/A'  \n",
    "                \n",
    "            # Track lyrics\n",
    "            track_lyrics = 'N/A'\n",
    "            \n",
    "            track_lyric_link = track.find('div',{'class':'info_link'}).a['href']            \n",
    "            if track_lyric_link and '#lyrics' in track_lyric_link:\n",
    "                lyric_tag = track.findNext('tr',{'class':'lyricsRow'})\n",
    "                track_lyrics = lyric_tag.find('td',{'colspan':'4'}).div.string.strip('\"').replace('\\r\\n','\\n')\n",
    "                all_lyrics += '\\n' + track_lyrics\n",
    "            \n",
    "            # Add track object to tracks list\n",
    "            track_obj = {'Track Title': track_title, 'Track Lyrics': track_lyrics,\n",
    "                        'Track Number': track_num, 'Track Duration': track_duration}\n",
    "            entry['Track Info'].append(track_obj)\n",
    "\n",
    "        if all_lyrics != '':\n",
    "            entry['All Lyrics'] = all_lyrics\n",
    "        else:\n",
    "            entry['All Lyrics'] = 'N/A'\n",
    "        \n",
    "        # Number of Tracks\n",
    "        entry['Number of Tracks'] = len(entry['Track Info'])\n",
    "        \n",
    "        # Popularity Index\n",
    "        entry['Number of Fans'] = 'N/A'\n",
    "        driver.get(URL)\n",
    "        foundAllFans = False\n",
    "        fan_pages_searched = 0\n",
    "        while foundAllFans == False and fan_pages_searched < MAX_FAN_PAGES:\n",
    "            try:\n",
    "                more_thumbs = driver.find_element_by_xpath('//a[@class=\"more-thumbs\"]')\n",
    "                fan_pages_searched += 1\n",
    "                if 'display: none' in more_thumbs.get_attribute(\"style\"):\n",
    "                    foundAllFans = True\n",
    "            except:\n",
    "                foundAllFans = True\n",
    "        \n",
    "        if fan_pages_searched == MAX_FAN_PAGES:\n",
    "            entry['Number of Fans'] = '>' + str(MAX_FANS)\n",
    "        else:\n",
    "            try:\n",
    "                parentElement = driver.find_element_by_xpath('//div[@class=\"no-writing\"]')\n",
    "                elementList = parentElement.find_elements_by_tag_name(\"a\")\n",
    "                entry['Number of Fans'] = len(elementList)                   \n",
    "            except:\n",
    "                entry['Number of Fans'] = 0\n",
    "                \n",
    "        if output == True:\n",
    "            #pprint(entry)\n",
    "            #print()\n",
    "            pass\n",
    "        \n",
    "        # add entry to scrape data\n",
    "        scrape_data.append(entry)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape search page function\n",
    "# scrape the number of pages in the given search URL\n",
    "def scrape_search_page(URL,num_pages=NUM_PAGES,output=False):\n",
    "\n",
    "    # read parameters from link\n",
    "    parameters = URL.split('?')[1:][0].split('&')\n",
    "    genre = 'all'\n",
    "    search_category = 'top'\n",
    "    location = 0\n",
    "    formatt = 'all'\n",
    "    subgenre = 'all'\n",
    "    week = 0\n",
    "    for parameter in parameters:\n",
    "        p = parameter.split('=')\n",
    "        if p[0] == 'g':\n",
    "            genre = p[1]\n",
    "        if p[0] == 's':\n",
    "            search_category = p[1]\n",
    "        if p[0] == 'gn':\n",
    "            location = int(p[1])\n",
    "        if p[0] == 'f':\n",
    "            formatt = p[1]\n",
    "        if p[0] == 't':\n",
    "            subgenre = p[1]\n",
    "        if p[0] == 'w':\n",
    "            week = int(p[1])\n",
    "    \n",
    "    print('scraping ' + category + ' ' + genre + ' (' + subgenre + ') albums from location \\'' + str(location) + '\\' in ' + formatt + ' format for week ' + str(week) + '...')\n",
    "    \n",
    "    entry = {'Release Genre': genre,\n",
    "            'Release Sub-Genre': subgenre,\n",
    "            'Search Format': formatt,\n",
    "            'Search Week': WEEK_DICT[week],\n",
    "            'Search Category': search_category}\n",
    "    \n",
    "    driver.get(URL)\n",
    "    time.sleep(INITIAL_SEARCH_WAIT)\n",
    "    \n",
    "    # extract URLs from link tags\n",
    "    release_URLS = []\n",
    "    \n",
    "    for i in range(num_pages):\n",
    "        # this is just to ensure that the page is loaded\n",
    "        \n",
    "        html = driver.page_source\n",
    "\n",
    "        # create bsoup object\n",
    "        soup = bsoup(str(html), 'lxml')\n",
    "\n",
    "        # find album link tags on this page\n",
    "        link_tags = soup.find_all('a', {'class':'item-title'})\n",
    "    \n",
    "        for tag in link_tags:\n",
    "            tag_url = tag['href'].split('?')[0]\n",
    "            if tag_url not in release_URLS and tag_url not in all_URLS_collected:\n",
    "                release_URLS.append(tag_url)\n",
    "        \n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//a[contains(text(), 'next')]\").click()\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    if output == True:\n",
    "        pprint(release_URLS)\n",
    "\n",
    "    for release_URL in release_URLS:\n",
    "        scrape_release_page(release_URL,entry,output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### USER INPUTS ######################################################\n",
    "\n",
    "# list of genres to scrape\n",
    "GENRES = ['all',\n",
    "          'rock',\n",
    "          'metal',\n",
    "          'alternative',\n",
    "          'hip-hop-rap',\n",
    "          'experimental',\n",
    "          'punk',\n",
    "          'pop',\n",
    "          'acoustic',\n",
    "          'funk',\n",
    "          'country',\n",
    "          'blues',\n",
    "          'ambient',\n",
    "          'soundtrack',\n",
    "          'world',\n",
    "          'jazz',\n",
    "          'r-b-soul',\n",
    "          'devotional',\n",
    "          'classical',\n",
    "          'reggae',\n",
    "          'latin']\n",
    "\n",
    "# scrape for subgenres within genres?\n",
    "SCRAPE_SUBGENRES = False\n",
    "\n",
    "# dictionary of subgenres to scrape, if scrape_subgenres = True\n",
    "SUBGENRES = {\n",
    "                'rock': ['indie','prog-rock','post-rock','rock-roll','psychedelic-rock'],\n",
    "                'metal': [],\n",
    "                'alternative': [],\n",
    "                'hip-hop-rap': [],\n",
    "                'experimental': [],\n",
    "                'punk': [],\n",
    "                'folk': [],\n",
    "                'pop': [],\n",
    "                'acoustic': [],\n",
    "                'funk': [],\n",
    "                'country': [],\n",
    "                'blues': []\n",
    "            }\n",
    "\n",
    "# list of search categories to scrape ['top', 'new', 'rec']\n",
    "#   top = best-selling\n",
    "#   new = new arrivals\n",
    "#   rec = artist-recommended\n",
    "SEARCH_CATEGORIES = ['top','new']\n",
    "\n",
    "# list of locations to scrape\n",
    "# location = 0 returns search results for all locations\n",
    "LOCATIONS = [0] \n",
    "\n",
    "# list of formats to scrape ['all','digital','vinyl','cd','cassette']\n",
    "FORMATS = ['all']\n",
    "\n",
    "# list of weeks to scrape\n",
    "# valid weeks: [-1,0,678,677,676,675,674,673]\n",
    "# today, this week, last week, 2, 3, 4, 5, 6 weeks ago\n",
    "WEEKS = [0]\n",
    "\n",
    "# include week parameter in search?\n",
    "SCRAPE_WEEKS = False\n",
    "\n",
    "# number of pages to scrape (10 produces 40-100 results)\n",
    "NUM_PAGES = 10 \n",
    "\n",
    "# Initial time to wait (in seconds) for Bandcamp Discover page to load\n",
    "INITIAL_SEARCH_WAIT = 5\n",
    "\n",
    "# retrieve no more than this many fans for popularity index\n",
    "MAX_FANS = 1000\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "# max number of pages of fan results to scrape before hitting MAX_FANS\n",
    "MAX_FAN_PAGES = int(MAX_FANS / 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping top all (all) albums from location '0' in all format for week 0...\n",
      "scraping new all (all) albums from location '0' in all format for week 0...\n",
      "scraping top rock (all) albums from location '0' in all format for week 0...\n",
      "scraping new rock (all) albums from location '0' in all format for week 0...\n",
      "scraping top metal (all) albums from location '0' in all format for week 0...\n",
      "scraping new metal (all) albums from location '0' in all format for week 0...\n",
      "scraping top alternative (all) albums from location '0' in all format for week 0...\n",
      "scraping new alternative (all) albums from location '0' in all format for week 0...\n",
      "scraping top hip-hop-rap (all) albums from location '0' in all format for week 0...\n",
      "scraping new hip-hop-rap (all) albums from location '0' in all format for week 0...\n",
      "scraping top experimental (all) albums from location '0' in all format for week 0...\n",
      "scraping new experimental (all) albums from location '0' in all format for week 0...\n",
      "scraping top punk (all) albums from location '0' in all format for week 0...\n",
      "scraping new punk (all) albums from location '0' in all format for week 0...\n",
      "scraping top pop (all) albums from location '0' in all format for week 0...\n",
      "scraping new pop (all) albums from location '0' in all format for week 0...\n",
      "scraping top acoustic (all) albums from location '0' in all format for week 0...\n",
      "scraping new acoustic (all) albums from location '0' in all format for week 0...\n",
      "scraping top funk (all) albums from location '0' in all format for week 0...\n",
      "scraping new funk (all) albums from location '0' in all format for week 0...\n",
      "scraping top country (all) albums from location '0' in all format for week 0...\n",
      "scraping new country (all) albums from location '0' in all format for week 0...\n",
      "scraping top blues (all) albums from location '0' in all format for week 0...\n",
      "scraping new blues (all) albums from location '0' in all format for week 0...\n",
      "scraping top ambient (all) albums from location '0' in all format for week 0...\n",
      "scraping new ambient (all) albums from location '0' in all format for week 0...\n",
      "scraping top soundtrack (all) albums from location '0' in all format for week 0...\n",
      "scraping new soundtrack (all) albums from location '0' in all format for week 0...\n",
      "scraping top world (all) albums from location '0' in all format for week 0...\n",
      "scraping new world (all) albums from location '0' in all format for week 0...\n",
      "scraping top jazz (all) albums from location '0' in all format for week 0...\n",
      "scraping new jazz (all) albums from location '0' in all format for week 0...\n",
      "scraping top r-b-soul (all) albums from location '0' in all format for week 0...\n",
      "scraping new r-b-soul (all) albums from location '0' in all format for week 0...\n",
      "scraping top devotional (all) albums from location '0' in all format for week 0...\n",
      "scraping new devotional (all) albums from location '0' in all format for week 0...\n",
      "scraping top classical (all) albums from location '0' in all format for week 0...\n",
      "scraping new classical (all) albums from location '0' in all format for week 0...\n",
      "scraping top reggae (all) albums from location '0' in all format for week 0...\n",
      "scraping new reggae (all) albums from location '0' in all format for week 0...\n",
      "scraping top latin (all) albums from location '0' in all format for week 0...\n",
      "scraping new latin (all) albums from location '0' in all format for week 0...\n"
     ]
    }
   ],
   "source": [
    "# main web scraper loop\n",
    "\n",
    "for genre in GENRES:\n",
    "    for category in SEARCH_CATEGORIES:\n",
    "        for location in LOCATIONS:\n",
    "            for formatt in FORMATS:\n",
    "                for week in WEEKS:\n",
    "                    if SCRAPE_WEEKS:\n",
    "                        scrape_URL = 'https://bandcamp.com/?g=' + genre + '&s=' + category + '&p=0' + '&gn=' + str(location) + '&f=' + formatt + '&w=' + str(week)\n",
    "                    else:\n",
    "                        scrape_URL = 'https://bandcamp.com/?g=' + genre + '&s=' + category + '&p=0' + '&gn=' + str(location) + '&f=' + formatt\n",
    "                        \n",
    "                    scrape_search_page(scrape_URL,output=False)\n",
    "                    \n",
    "                    if SCRAPE_SUBGENRES and genre in SUBGENRES:\n",
    "                        for subgenre in SUBGENRES[genre]:\n",
    "                            subgenre_scrape_URL = scrape_URL + '&t=' + subgenre\n",
    "                            scrape_search_page(subgenre_scrape_URL,output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOHN KING CAVE scrapes\n",
    "\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/album/devil-rides-beside',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/album/oh-my-love',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/album/emotion-tread-light',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/album/720-split',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/album/sing-a-song',{'Release Genre':'folk'})\n",
    "\n",
    "# NOTE: Doesn't work for Bandcamp track pages\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/track/i-love-america',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/track/shes-coming-down-the-line-2',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/track/labyrinth-of-faith',{'Release Genre':'folk'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Genre</th>\n",
       "      <th>Release Sub-Genre</th>\n",
       "      <th>Search Format</th>\n",
       "      <th>Search Week</th>\n",
       "      <th>Search Category</th>\n",
       "      <th>Release URL</th>\n",
       "      <th>Scrape Date</th>\n",
       "      <th>Release Title</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Artist Location</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Track Info</th>\n",
       "      <th>All Lyrics</th>\n",
       "      <th>Number of Tracks</th>\n",
       "      <th>Number of Fans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>top</td>\n",
       "      <td>https://tossportal.bandcamp.com/album/still-sl...</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>still slipping vol. 1</td>\n",
       "      <td>Joy Orbison</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>[electronic, London]</td>\n",
       "      <td>[{'Track Title': 'w/ dad &amp; frankie', 'Track Ly...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>14</td>\n",
       "      <td>&gt;1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>top</td>\n",
       "      <td>https://newretrowave.bandcamp.com/album/love-k...</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>Love Kills the Demon</td>\n",
       "      <td>ORAX</td>\n",
       "      <td>New York, New York</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>[80s, 90s, electronic, darksynth, dreamwave, n...</td>\n",
       "      <td>[{'Track Title': 'Despair', 'Track Lyrics': 'N...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>13</td>\n",
       "      <td>&gt;1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>top</td>\n",
       "      <td>https://orangemilkrecords.bandcamp.com/album/w...</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>WLFGRL vinyl</td>\n",
       "      <td>Machine Girl</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-08-09</td>\n",
       "      <td>[new york, breakcore, drum and bass, juke, jun...</td>\n",
       "      <td>[{'Track Title': 'MG1', 'Track Lyrics': 'N/A',...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>17</td>\n",
       "      <td>&gt;1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>top</td>\n",
       "      <td>https://godisinthetvzine.bandcamp.com/album/a-...</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>A Carnival of Sorts: An R.E.M. covers compilation</td>\n",
       "      <td>Various Artists</td>\n",
       "      <td>Cardiff, UK</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>[help musicians, r.e.m., r.e.m. covers, Cardiff]</td>\n",
       "      <td>[{'Track Title': 'Finest Worksong', 'Track Lyr...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>top</td>\n",
       "      <td>https://projektrecords.bandcamp.com/album/kits...</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>Kitsune (name-your-price)</td>\n",
       "      <td>jarguna &amp; Ryuzen</td>\n",
       "      <td>Portland, Oregon</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>[electronic, alternative, ambient, experimenta...</td>\n",
       "      <td>[{'Track Title': 'Kubinodanza', 'Track Lyrics'...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>10</td>\n",
       "      <td>&gt;1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>latin</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>new</td>\n",
       "      <td>https://discoshoroscopo.bandcamp.com/album/par...</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>Parque Tropical Del Amor</td>\n",
       "      <td>Los Super Amigos</td>\n",
       "      <td>Madrid, Spain</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>[latin, chicha, cumbia, psychedelic, rock, Mad...</td>\n",
       "      <td>[{'Track Title': 'Cholita', 'Track Lyrics': 'N...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>latin</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>new</td>\n",
       "      <td>https://chachocosmico.bandcamp.com/album/nueve...</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>Nueve Canciones de Amor y Dos Cumbias Castellanas</td>\n",
       "      <td>Chacho Cósmico</td>\n",
       "      <td>Valladolid, Spain</td>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>[autotune, cumbia, dub, latin, merengue, salsa...</td>\n",
       "      <td>[{'Track Title': 'La Danza de los Zánganos', '...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>latin</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>new</td>\n",
       "      <td>https://conderodriguez.bandcamp.com/album/less...</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>Less Drums</td>\n",
       "      <td>Conde Rodríguez</td>\n",
       "      <td>Valencia, Venezuela</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>[hip hop, latin, Valencia]</td>\n",
       "      <td>[{'Track Title': 'Nothing Can Stop Me', 'Track...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>latin</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>new</td>\n",
       "      <td>https://elmayonesa.bandcamp.com/album/blumenst...</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>BLUMENSTEIGER</td>\n",
       "      <td>Elmayonesa Kobra Selbstmeisterung</td>\n",
       "      <td>Mendoza Province, Argentina</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>[latin, classical, field recordings, freestyle...</td>\n",
       "      <td>[{'Track Title': 'Bedeutung Erklärung Affirmat...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>latin</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>new</td>\n",
       "      <td>https://beatzbychris.bandcamp.com/album/trap</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>Trap</td>\n",
       "      <td>Beatzbychris</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>[latin, reggaeton, trap, dancehall, Puerto Rico]</td>\n",
       "      <td>[{'Track Title': 'Coast to Coast', 'Track Lyri...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Release Genre Release Sub-Genre Search Format Search Week Search Category  \\\n",
       "0             all               all           all   this week             top   \n",
       "1             all               all           all   this week             top   \n",
       "2             all               all           all   this week             top   \n",
       "3             all               all           all   this week             top   \n",
       "4             all               all           all   this week             top   \n",
       "..            ...               ...           ...         ...             ...   \n",
       "496         latin               all           all   this week             new   \n",
       "497         latin               all           all   this week             new   \n",
       "498         latin               all           all   this week             new   \n",
       "499         latin               all           all   this week             new   \n",
       "500         latin               all           all   this week             new   \n",
       "\n",
       "                                           Release URL Scrape Date  \\\n",
       "0    https://tossportal.bandcamp.com/album/still-sl...  2021-08-18   \n",
       "1    https://newretrowave.bandcamp.com/album/love-k...  2021-08-18   \n",
       "2    https://orangemilkrecords.bandcamp.com/album/w...  2021-08-18   \n",
       "3    https://godisinthetvzine.bandcamp.com/album/a-...  2021-08-18   \n",
       "4    https://projektrecords.bandcamp.com/album/kits...  2021-08-18   \n",
       "..                                                 ...         ...   \n",
       "496  https://discoshoroscopo.bandcamp.com/album/par...  2021-08-18   \n",
       "497  https://chachocosmico.bandcamp.com/album/nueve...  2021-08-18   \n",
       "498  https://conderodriguez.bandcamp.com/album/less...  2021-08-18   \n",
       "499  https://elmayonesa.bandcamp.com/album/blumenst...  2021-08-18   \n",
       "500       https://beatzbychris.bandcamp.com/album/trap  2021-08-18   \n",
       "\n",
       "                                         Release Title  \\\n",
       "0                                still slipping vol. 1   \n",
       "1                                 Love Kills the Demon   \n",
       "2                                         WLFGRL vinyl   \n",
       "3    A Carnival of Sorts: An R.E.M. covers compilation   \n",
       "4                            Kitsune (name-your-price)   \n",
       "..                                                 ...   \n",
       "496                           Parque Tropical Del Amor   \n",
       "497  Nueve Canciones de Amor y Dos Cumbias Castellanas   \n",
       "498                                         Less Drums   \n",
       "499                                      BLUMENSTEIGER   \n",
       "500                                               Trap   \n",
       "\n",
       "                           Artist Name              Artist Location  \\\n",
       "0                          Joy Orbison                   London, UK   \n",
       "1                                 ORAX           New York, New York   \n",
       "2                         Machine Girl                         None   \n",
       "3                      Various Artists                  Cardiff, UK   \n",
       "4                     jarguna & Ryuzen             Portland, Oregon   \n",
       "..                                 ...                          ...   \n",
       "496                   Los Super Amigos                Madrid, Spain   \n",
       "497                     Chacho Cósmico            Valladolid, Spain   \n",
       "498                    Conde Rodríguez          Valencia, Venezuela   \n",
       "499  Elmayonesa Kobra Selbstmeisterung  Mendoza Province, Argentina   \n",
       "500                       Beatzbychris                  Puerto Rico   \n",
       "\n",
       "    Release Date                                               Tags  \\\n",
       "0     2021-08-13                               [electronic, London]   \n",
       "1     2021-08-20  [80s, 90s, electronic, darksynth, dreamwave, n...   \n",
       "2     2021-08-09  [new york, breakcore, drum and bass, juke, jun...   \n",
       "3     2021-08-20   [help musicians, r.e.m., r.e.m. covers, Cardiff]   \n",
       "4     2021-08-17  [electronic, alternative, ambient, experimenta...   \n",
       "..           ...                                                ...   \n",
       "496   2021-08-18  [latin, chicha, cumbia, psychedelic, rock, Mad...   \n",
       "497   2021-08-25  [autotune, cumbia, dub, latin, merengue, salsa...   \n",
       "498   2021-08-16                         [hip hop, latin, Valencia]   \n",
       "499   2021-08-16  [latin, classical, field recordings, freestyle...   \n",
       "500   2021-08-16   [latin, reggaeton, trap, dancehall, Puerto Rico]   \n",
       "\n",
       "                                            Track Info All Lyrics  \\\n",
       "0    [{'Track Title': 'w/ dad & frankie', 'Track Ly...        N/A   \n",
       "1    [{'Track Title': 'Despair', 'Track Lyrics': 'N...        N/A   \n",
       "2    [{'Track Title': 'MG1', 'Track Lyrics': 'N/A',...        N/A   \n",
       "3    [{'Track Title': 'Finest Worksong', 'Track Lyr...        N/A   \n",
       "4    [{'Track Title': 'Kubinodanza', 'Track Lyrics'...        N/A   \n",
       "..                                                 ...        ...   \n",
       "496  [{'Track Title': 'Cholita', 'Track Lyrics': 'N...        N/A   \n",
       "497  [{'Track Title': 'La Danza de los Zánganos', '...        N/A   \n",
       "498  [{'Track Title': 'Nothing Can Stop Me', 'Track...        N/A   \n",
       "499  [{'Track Title': 'Bedeutung Erklärung Affirmat...        N/A   \n",
       "500  [{'Track Title': 'Coast to Coast', 'Track Lyri...        N/A   \n",
       "\n",
       "     Number of Tracks Number of Fans  \n",
       "0                  14          >1000  \n",
       "1                  13          >1000  \n",
       "2                  17          >1000  \n",
       "3                  40          >1000  \n",
       "4                  10          >1000  \n",
       "..                ...            ...  \n",
       "496                11              0  \n",
       "497                11              0  \n",
       "498                 7              0  \n",
       "499                 4              0  \n",
       "500                 1              0  \n",
       "\n",
       "[501 rows x 16 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Dataframe\n",
    "scrape_df = pd.DataFrame(scrape_data)\n",
    "scrape_df = scrape_df.drop_duplicates(subset = [\"Release URL\"])\n",
    "\n",
    "scrape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to CSV\n",
    "\n",
    "timestamp = time.strftime('%b-%d-%Y_%H%M%S')\n",
    "scrape_df.to_csv('scrape_data_' + timestamp + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save collected URLS (to be loaded for next batch)\n",
    "with open(\"all_URLS_collected.txt\", \"w\") as fp:\n",
    "    json.dump(all_URLS_collected, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
