{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bsoup\n",
    "import urllib.robotparser\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "import time\n",
    "import dateparser\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GeckoDriverManager module.\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "# Install the GeckoDriverManager to run FireFox web browser (for the first time!)\n",
    "# driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "\n",
    "# Once driver is installed, use this line:\n",
    "driver = webdriver.Firefox(executable_path='./geckodriver.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandcamp Web Scraper Data format information\n",
    "\n",
    "'''\n",
    "\n",
    "scrape_data = pd.DataFrame(columns=['Release Title', \n",
    "                                    'Artist Name', \n",
    "                                    'Artist Location',\n",
    "                                    'Release Date',\n",
    "                                    'Release URL',\n",
    "                                    'Release Genre',\n",
    "                                    'Release Sub-Genre',\n",
    "                                    'Search Format',\n",
    "                                    'Search Week',\n",
    "                                    'Search Category',\n",
    "                                    'All Lyrics',\n",
    "                                    'Number of Tracks'\n",
    "                                    'Track Info',\n",
    "                                    'Number of Fans',\n",
    "                                    'Tags',\n",
    "                                    'Scrape Date'])\n",
    "                                    \n",
    "### dictionary entry for track listing\n",
    "\n",
    "track_info_entry = {\n",
    "    'Track Title' : '',\n",
    "    'Track Lyrics' : '',\n",
    "    'Track Number' : '#',\n",
    "    'Track Duration': '##:##'\n",
    "}\n",
    "                                    \n",
    "'''\n",
    "\n",
    "# valid weeks: [-1,0,678,677,676,675,674,673]\n",
    "# today, this week, last week, 2, 3, 4, 5, 6 weeks ago\n",
    "WEEK_DICT = {\n",
    "    -1:'today',\n",
    "    0:'this week',\n",
    "    678:'last week',\n",
    "    677:'2 weeks ago',\n",
    "    676:'3 weeks ago',\n",
    "    675:'4 weeks ago',\n",
    "    674:'5 weeks ago',\n",
    "    673:'6 weeks ago'\n",
    "}\n",
    "\n",
    "# scrape dataframe list to collect release entries\n",
    "scrape_data = []\n",
    "\n",
    "# all URLS collected so far (don't collect duplicate albums for multiple searches)\n",
    "# load 'all_URLS_collected.txt' file if it exists\n",
    "all_URLS_collected = []\n",
    "URLS_file = Path(\"all_URLS_collected.txt\")\n",
    "if URLS_file.is_file():\n",
    "    with open(\"all_URLS_collected.txt\", \"r\") as fp:\n",
    "        all_URLS_collected = json.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape bandcamp release page function\n",
    "def scrape_release_page(URL,entry,output=False):\n",
    "    \n",
    "    entry = entry.copy()\n",
    "    \n",
    "    entry['Release URL'] = URL\n",
    "    entry['Scrape Date'] = datetime.datetime.now().date()\n",
    "    \n",
    "    # don't add entry if it already exists in scrape dataframe\n",
    "    if URL in all_URLS_collected:\n",
    "        return\n",
    "    else:\n",
    "        all_URLS_collected.append(URL)\n",
    "    \n",
    "    if output==True:\n",
    "        print('retrieving info for ' + URL + ' ...')\n",
    "\n",
    "    headers = {'user-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(URL,headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "\n",
    "        soup = bsoup(response.text, 'lxml')\n",
    "        \n",
    "        # Get title and artist name\n",
    "        title = soup.find('meta',{'name':'title'})['content'].split(', by ')\n",
    "        entry['Release Title'] = title[0]\n",
    "        entry['Artist Name'] = title[1]\n",
    "        \n",
    "        # Get artist location\n",
    "        entry['Artist Location'] = soup.find('span',{'class':'location secondaryText'}).string\n",
    "        \n",
    "        # Get release date\n",
    "        release_date = soup.find('div',{'class':'tralbumData tralbum-credits'}).contents[0].string.strip('\"').strip(' ').replace('releases','').replace('released','')\n",
    "        release_date = dateparser.parse(release_date)\n",
    "        entry['Release Date'] = release_date\n",
    "        \n",
    "        # Get tags\n",
    "        tags = soup.find_all('a',{'class':'tag'})\n",
    "        tags_list = []\n",
    "        for tag in tags:\n",
    "            tags_list.append(tag.string)\n",
    "        entry['Tags'] = tags_list\n",
    "        \n",
    "        # If no genre in entry, leave blank\n",
    "        if 'Release Genre' not in entry:\n",
    "            entry['Release Genre'] = 'N/A'\n",
    "            \n",
    "        # If no subgenre in entry, leave blank\n",
    "        if 'Release Sub-Genre' not in entry:\n",
    "            entry['Release Sub-Genre'] = 'N/A'            \n",
    "        \n",
    "        # Get track information\n",
    "        entry['Track Info'] = []\n",
    "        #tracks = soup.find('table',{'id':'track_table'}).findChildren('tr', recursive=False)\n",
    "        tracks = soup.find('table',{'id':'track_table'}).find_all('tr',{'class':'track_row_view'})\n",
    "        \n",
    "        all_lyrics = ''\n",
    "        for track in tracks:\n",
    "            # Track number\n",
    "            track_num = int(track.find('td',{'class':'track-number-col'}).div.string.strip('.'))\n",
    "\n",
    "            # Track title\n",
    "            track_title = track.find('span',{'class':'track-title'})\n",
    "            if track_title:\n",
    "                track_title = track_title.string\n",
    "            else:\n",
    "                track_title = track.find('div',{'class':'title'}).span.string\n",
    "        \n",
    "            # Track duration\n",
    "            track_duration = track.find('span',{'class':'time secondaryText'})\n",
    "            if track_duration:\n",
    "                track_duration = track_duration.string.replace('\\n','').strip(' ')\n",
    "            else:\n",
    "                track_duration = 'N/A'  \n",
    "                \n",
    "            # Track lyrics\n",
    "            track_lyrics = 'N/A'\n",
    "            \n",
    "            track_lyric_link = track.find('div',{'class':'info_link'}).a['href']            \n",
    "            if track_lyric_link and '#lyrics' in track_lyric_link:\n",
    "                lyric_tag = track.findNext('tr',{'class':'lyricsRow'})\n",
    "                track_lyrics = lyric_tag.find('td',{'colspan':'4'}).div.string.strip('\"').replace('\\r\\n','\\n')\n",
    "                all_lyrics += '\\n' + track_lyrics\n",
    "            \n",
    "            # Add track object to tracks list\n",
    "            track_obj = {'Track Title': track_title, 'Track Lyrics': track_lyrics,\n",
    "                        'Track Number': track_num, 'Track Duration': track_duration}\n",
    "            entry['Track Info'].append(track_obj)\n",
    "\n",
    "        if all_lyrics != '':\n",
    "            entry['All Lyrics'] = all_lyrics\n",
    "        else:\n",
    "            entry['All Lyrics'] = 'N/A'\n",
    "        \n",
    "        # Number of Tracks\n",
    "        entry['Number of Tracks'] = len(entry['Track Info'])\n",
    "        \n",
    "        # Popularity Index\n",
    "        '''\n",
    "        entry['Number of Fans'] = 'N/A'\n",
    "        driver.get(URL)\n",
    "        foundAllFans = False\n",
    "        fan_pages_searched = 0\n",
    "\n",
    "        more_thumbs = None\n",
    "        try:\n",
    "            more_thumbs = driver.find_element_by_xpath('//a[@class=\"more-thumbs\"]')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if more_thumbs != None:\n",
    "            \n",
    "            while foundAllFans == False and fan_pages_searched < MAX_FAN_PAGES:\n",
    "            \n",
    "                fan_pages_searched += 1\n",
    "                if 'display: none' not in more_thumbs.get_attribute(\"style\"):\n",
    "                    more_thumbs.click()\n",
    "                    print('page: ', fan_pages_searched)\n",
    "                else:\n",
    "                    foundAllFans = True\n",
    "        \n",
    "        if fan_pages_searched == MAX_FAN_PAGES:\n",
    "            entry['Number of Fans'] = '>' + str(MAX_FANS)\n",
    "        else:\n",
    "            #entry['Number of Fans'] = fan_pages_searched * 60\n",
    "            \n",
    "            try:\n",
    "                parentElement = driver.find_element_by_xpath('//div[@class=\"no-writing\"]')\n",
    "                elementList = parentElement.find_elements_by_tag_name(\"a\")\n",
    "                entry['Number of Fans'] = len(elementList)                   \n",
    "            except:\n",
    "                entry['Number of Fans'] = 0\n",
    "        '''\n",
    "                \n",
    "        if output == True:\n",
    "            #pprint(entry)\n",
    "            #print()\n",
    "            pass\n",
    "        \n",
    "        # add entry to scrape data\n",
    "        scrape_data.append(entry)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape search page function\n",
    "# scrape the number of pages in the given search URL\n",
    "def scrape_search_page(URL,num_pages=NUM_PAGES,output=False):\n",
    "\n",
    "    # read parameters from link\n",
    "    parameters = URL.split('?')[1:][0].split('&')\n",
    "    genre = 'all'\n",
    "    search_category = 'top'\n",
    "    location = 0\n",
    "    formatt = 'all'\n",
    "    subgenre = 'all'\n",
    "    week = 0\n",
    "    for parameter in parameters:\n",
    "        p = parameter.split('=')\n",
    "        if p[0] == 'g':\n",
    "            genre = p[1]\n",
    "        if p[0] == 's':\n",
    "            search_category = p[1]\n",
    "        if p[0] == 'gn':\n",
    "            location = int(p[1])\n",
    "        if p[0] == 'f':\n",
    "            formatt = p[1]\n",
    "        if p[0] == 't':\n",
    "            subgenre = p[1]\n",
    "        if p[0] == 'w':\n",
    "            week = int(p[1])\n",
    "    \n",
    "    print('scraping ' + category + ' ' + genre + ' (' + subgenre + ') albums from location \\'' + str(location) + '\\' in ' + formatt + ' format for week ' + str(week) + '...')\n",
    "    \n",
    "    entry = {'Release Genre': genre,\n",
    "            'Release Sub-Genre': subgenre,\n",
    "            'Search Format': formatt,\n",
    "            'Search Week': WEEK_DICT[week],\n",
    "            'Search Category': search_category}\n",
    "    \n",
    "    driver.get(URL)\n",
    "    time.sleep(INITIAL_SEARCH_WAIT)\n",
    "    \n",
    "    # extract URLs from link tags\n",
    "    release_URLS = []\n",
    "    \n",
    "    for i in range(num_pages):\n",
    "        # this is just to ensure that the page is loaded\n",
    "        \n",
    "        html = driver.page_source\n",
    "\n",
    "        # create bsoup object\n",
    "        soup = bsoup(str(html), 'lxml')\n",
    "\n",
    "        # find album link tags on this page\n",
    "        link_tags = soup.find_all('a', {'class':'item-title'})\n",
    "    \n",
    "        for tag in link_tags:\n",
    "            tag_url = tag['href'].split('?')[0]\n",
    "            if tag_url not in release_URLS and tag_url not in all_URLS_collected:\n",
    "                release_URLS.append(tag_url)\n",
    "        \n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//a[contains(text(), 'next')]\").click()\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    if output == True:\n",
    "        pprint(release_URLS)\n",
    "\n",
    "    for release_URL in release_URLS:\n",
    "        scrape_release_page(release_URL,entry,output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### USER INPUTS ######################################################\n",
    "\n",
    "# list of genres to scrape\n",
    "GENRES = ['all',\n",
    "          'rock',\n",
    "          #'metal',\n",
    "          'alternative',\n",
    "          'hip-hop-rap',\n",
    "          'experimental',\n",
    "          #'punk',\n",
    "          'pop',\n",
    "          'acoustic',\n",
    "          #'funk',\n",
    "          'country',\n",
    "          'blues',\n",
    "          #'ambient',\n",
    "          #'soundtrack',\n",
    "          #'world',\n",
    "          'jazz',\n",
    "          'r-b-soul',\n",
    "          #'devotional',\n",
    "          #'classical',\n",
    "          'reggae'\n",
    "          #'latin'\n",
    "         ]\n",
    "\n",
    "# scrape for subgenres within genres?\n",
    "SCRAPE_SUBGENRES = False\n",
    "\n",
    "# dictionary of subgenres to scrape, if scrape_subgenres = True\n",
    "SUBGENRES = {\n",
    "                'rock': ['indie','prog-rock','post-rock','rock-roll','psychedelic-rock'],\n",
    "                'metal': [],\n",
    "                'alternative': [],\n",
    "                'hip-hop-rap': [],\n",
    "                'experimental': [],\n",
    "                'punk': [],\n",
    "                'folk': [],\n",
    "                'pop': [],\n",
    "                'acoustic': [],\n",
    "                'funk': [],\n",
    "                'country': [],\n",
    "                'blues': []\n",
    "            }\n",
    "\n",
    "# list of search categories to scrape ['top', 'new', 'rec']\n",
    "#   top = best-selling\n",
    "#   new = new arrivals\n",
    "#   rec = artist-recommended\n",
    "SEARCH_CATEGORIES = ['top','new']\n",
    "\n",
    "# list of locations to scrape\n",
    "# location = 0 returns search results for all locations\n",
    "LOCATIONS = [0] \n",
    "\n",
    "# list of formats to scrape ['all','digital','vinyl','cd','cassette']\n",
    "FORMATS = ['all']\n",
    "\n",
    "# list of weeks to scrape\n",
    "# valid weeks: [-1,0,678,677,676,675,674,673]\n",
    "# today, this week, last week, 2, 3, 4, 5, 6 weeks ago\n",
    "WEEKS = [0,676,673]\n",
    "\n",
    "# include week parameter in search?\n",
    "SCRAPE_WEEKS = True\n",
    "\n",
    "# number of pages to scrape (10 produces 40-100 results)\n",
    "NUM_PAGES = 13\n",
    "\n",
    "# Initial time to wait (in seconds) for Bandcamp Discover page to load\n",
    "INITIAL_SEARCH_WAIT = 5\n",
    "\n",
    "# retrieve no more than this many fans for popularity index\n",
    "MAX_FANS = 0\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "# max number of pages of fan results to scrape before hitting MAX_FANS\n",
    "MAX_FAN_PAGES = int(MAX_FANS / 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping top all (all) albums from location '0' in all format for week 0...\n",
      "scraping top all (all) albums from location '0' in all format for week 676...\n",
      "scraping top all (all) albums from location '0' in all format for week 673...\n",
      "scraping new all (all) albums from location '0' in all format for week 0...\n",
      "scraping new all (all) albums from location '0' in all format for week 676...\n",
      "scraping new all (all) albums from location '0' in all format for week 673...\n",
      "scraping top rock (all) albums from location '0' in all format for week 0...\n",
      "scraping top rock (all) albums from location '0' in all format for week 676...\n",
      "scraping top rock (all) albums from location '0' in all format for week 673...\n",
      "scraping new rock (all) albums from location '0' in all format for week 0...\n",
      "scraping new rock (all) albums from location '0' in all format for week 676...\n",
      "scraping new rock (all) albums from location '0' in all format for week 673...\n",
      "scraping top alternative (all) albums from location '0' in all format for week 0...\n",
      "scraping top alternative (all) albums from location '0' in all format for week 676...\n",
      "scraping top alternative (all) albums from location '0' in all format for week 673...\n",
      "scraping new alternative (all) albums from location '0' in all format for week 0...\n",
      "scraping new alternative (all) albums from location '0' in all format for week 676...\n",
      "scraping new alternative (all) albums from location '0' in all format for week 673...\n",
      "scraping top hip-hop-rap (all) albums from location '0' in all format for week 0...\n",
      "scraping top hip-hop-rap (all) albums from location '0' in all format for week 676...\n",
      "scraping top hip-hop-rap (all) albums from location '0' in all format for week 673...\n",
      "scraping new hip-hop-rap (all) albums from location '0' in all format for week 0...\n",
      "scraping new hip-hop-rap (all) albums from location '0' in all format for week 676...\n",
      "scraping new hip-hop-rap (all) albums from location '0' in all format for week 673...\n",
      "scraping top experimental (all) albums from location '0' in all format for week 0...\n",
      "scraping top experimental (all) albums from location '0' in all format for week 676...\n",
      "scraping top experimental (all) albums from location '0' in all format for week 673...\n",
      "scraping new experimental (all) albums from location '0' in all format for week 0...\n",
      "scraping new experimental (all) albums from location '0' in all format for week 676...\n",
      "scraping new experimental (all) albums from location '0' in all format for week 673...\n",
      "scraping top pop (all) albums from location '0' in all format for week 0...\n",
      "scraping top pop (all) albums from location '0' in all format for week 676...\n",
      "scraping top pop (all) albums from location '0' in all format for week 673...\n",
      "scraping new pop (all) albums from location '0' in all format for week 0...\n",
      "scraping new pop (all) albums from location '0' in all format for week 676...\n",
      "scraping new pop (all) albums from location '0' in all format for week 673...\n",
      "scraping top acoustic (all) albums from location '0' in all format for week 0...\n",
      "scraping top acoustic (all) albums from location '0' in all format for week 676...\n",
      "scraping top acoustic (all) albums from location '0' in all format for week 673...\n",
      "scraping new acoustic (all) albums from location '0' in all format for week 0...\n",
      "scraping new acoustic (all) albums from location '0' in all format for week 676...\n",
      "scraping new acoustic (all) albums from location '0' in all format for week 673...\n",
      "scraping top country (all) albums from location '0' in all format for week 0...\n",
      "scraping top country (all) albums from location '0' in all format for week 676...\n",
      "scraping top country (all) albums from location '0' in all format for week 673...\n",
      "scraping new country (all) albums from location '0' in all format for week 0...\n",
      "scraping new country (all) albums from location '0' in all format for week 676...\n",
      "scraping new country (all) albums from location '0' in all format for week 673...\n",
      "scraping top blues (all) albums from location '0' in all format for week 0...\n",
      "scraping top blues (all) albums from location '0' in all format for week 676...\n",
      "scraping top blues (all) albums from location '0' in all format for week 673...\n",
      "scraping new blues (all) albums from location '0' in all format for week 0...\n",
      "scraping new blues (all) albums from location '0' in all format for week 676...\n",
      "scraping new blues (all) albums from location '0' in all format for week 673...\n",
      "scraping top jazz (all) albums from location '0' in all format for week 0...\n",
      "scraping top jazz (all) albums from location '0' in all format for week 676...\n",
      "scraping top jazz (all) albums from location '0' in all format for week 673...\n",
      "scraping new jazz (all) albums from location '0' in all format for week 0...\n",
      "scraping new jazz (all) albums from location '0' in all format for week 676...\n",
      "scraping new jazz (all) albums from location '0' in all format for week 673...\n",
      "scraping top r-b-soul (all) albums from location '0' in all format for week 0...\n",
      "scraping top r-b-soul (all) albums from location '0' in all format for week 676...\n",
      "scraping top r-b-soul (all) albums from location '0' in all format for week 673...\n",
      "scraping new r-b-soul (all) albums from location '0' in all format for week 0...\n",
      "scraping new r-b-soul (all) albums from location '0' in all format for week 676...\n",
      "scraping new r-b-soul (all) albums from location '0' in all format for week 673...\n",
      "scraping top reggae (all) albums from location '0' in all format for week 0...\n",
      "scraping top reggae (all) albums from location '0' in all format for week 676...\n",
      "scraping top reggae (all) albums from location '0' in all format for week 673...\n",
      "scraping new reggae (all) albums from location '0' in all format for week 0...\n",
      "scraping new reggae (all) albums from location '0' in all format for week 676...\n",
      "scraping new reggae (all) albums from location '0' in all format for week 673...\n"
     ]
    }
   ],
   "source": [
    "# main web scraper loop\n",
    "\n",
    "for genre in GENRES:\n",
    "    for category in SEARCH_CATEGORIES:\n",
    "        for location in LOCATIONS:\n",
    "            for formatt in FORMATS:\n",
    "                for week in WEEKS:\n",
    "                    if SCRAPE_WEEKS:\n",
    "                        scrape_URL = 'https://bandcamp.com/?g=' + genre + '&s=' + category + '&p=0' + '&gn=' + str(location) + '&f=' + formatt + '&w=' + str(week)\n",
    "                    else:\n",
    "                        scrape_URL = 'https://bandcamp.com/?g=' + genre + '&s=' + category + '&p=0' + '&gn=' + str(location) + '&f=' + formatt\n",
    "                        \n",
    "                    scrape_search_page(scrape_URL,output=False)\n",
    "                    \n",
    "                    if SCRAPE_SUBGENRES and genre in SUBGENRES:\n",
    "                        for subgenre in SUBGENRES[genre]:\n",
    "                            subgenre_scrape_URL = scrape_URL + '&t=' + subgenre\n",
    "                            scrape_search_page(subgenre_scrape_URL,output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOHN KING CAVE scrapes\n",
    "\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/album/devil-rides-beside',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/album/oh-my-love',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/album/emotion-tread-light',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/album/720-split',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/album/sing-a-song',{'Release Genre':'folk'})\n",
    "\n",
    "# NOTE: Doesn't work for Bandcamp track pages\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/track/i-love-america',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/track/shes-coming-down-the-line-2',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/track/labyrinth-of-faith',{'Release Genre':'folk'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Genre</th>\n",
       "      <th>Release Sub-Genre</th>\n",
       "      <th>Search Format</th>\n",
       "      <th>Search Week</th>\n",
       "      <th>Search Category</th>\n",
       "      <th>Release URL</th>\n",
       "      <th>Scrape Date</th>\n",
       "      <th>Release Title</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Artist Location</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Track Info</th>\n",
       "      <th>All Lyrics</th>\n",
       "      <th>Number of Tracks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>top</td>\n",
       "      <td>https://parquetcourts.bandcamp.com/album/sympa...</td>\n",
       "      <td>2021-08-19</td>\n",
       "      <td>Sympathy for Life</td>\n",
       "      <td>Parquet Courts</td>\n",
       "      <td>Brooklyn, New York</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>[alternative, indie rock, New York]</td>\n",
       "      <td>[{'Track Title': 'Walking at a Downtown Pace',...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>top</td>\n",
       "      <td>https://portrayalofguilt.bandcamp.com/album/po...</td>\n",
       "      <td>2021-08-19</td>\n",
       "      <td>portrayal of guilt / Chat Pile Split</td>\n",
       "      <td>portrayal of guilt</td>\n",
       "      <td>Austin, Texas</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>[punk, black metal, hardcore, metal, post-hard...</td>\n",
       "      <td>[{'Track Title': 'Touched by an Angel', 'Track...</td>\n",
       "      <td>\\nMy mind, tortured and depraved.\\nDissolving....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>top</td>\n",
       "      <td>https://johncarpentermusic.bandcamp.com/album/...</td>\n",
       "      <td>2021-08-19</td>\n",
       "      <td>Halloween Kills OST</td>\n",
       "      <td>John Carpenter</td>\n",
       "      <td>Los Angeles, California</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>[alternative, electronic, new age, prog-rock, ...</td>\n",
       "      <td>[{'Track Title': 'Logos Kill', 'Track Lyrics':...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>top</td>\n",
       "      <td>https://tossportal.bandcamp.com/album/still-sl...</td>\n",
       "      <td>2021-08-19</td>\n",
       "      <td>still slipping vol. 1</td>\n",
       "      <td>Joy Orbison</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>[electronic, London]</td>\n",
       "      <td>[{'Track Title': 'w/ dad &amp; frankie', 'Track Ly...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>this week</td>\n",
       "      <td>top</td>\n",
       "      <td>https://grouchnz.bandcamp.com/album/rare-speci...</td>\n",
       "      <td>2021-08-19</td>\n",
       "      <td>Rare Specimens</td>\n",
       "      <td>Grouch / Grouch In Dub</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>[dub, electronic, grouch, psychedelic, techo, ...</td>\n",
       "      <td>[{'Track Title': 'Right Lymph Node', 'Track Ly...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5611</th>\n",
       "      <td>reggae</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>6 weeks ago</td>\n",
       "      <td>new</td>\n",
       "      <td>https://wildmanriddim.bandcamp.com/album/s-t</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>S/T</td>\n",
       "      <td>Wild Man Riddim</td>\n",
       "      <td>Oslo, Norway</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>[afrobeat, reggae, jazz, ska, skajazz, world, ...</td>\n",
       "      <td>[{'Track Title': 'Breskus Rex', 'Track Lyrics'...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5612</th>\n",
       "      <td>reggae</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>6 weeks ago</td>\n",
       "      <td>new</td>\n",
       "      <td>https://basscultureplayers.bandcamp.com/album/...</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>War Refugees</td>\n",
       "      <td>Old John / Bass Culture Players</td>\n",
       "      <td>Madrid, Spain</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>[reggae, athens, bass culture players, dub, ma...</td>\n",
       "      <td>[{'Track Title': 'War Refugees', 'Track Lyrics...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5613</th>\n",
       "      <td>reggae</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>6 weeks ago</td>\n",
       "      <td>new</td>\n",
       "      <td>https://rastenda.bandcamp.com/album/rise-up-time</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>Rise Up Time</td>\n",
       "      <td>Ras Tenda /Sister Defender</td>\n",
       "      <td>UK</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>[reggae, roots &amp; culture, roots and culture, U...</td>\n",
       "      <td>[{'Track Title': 'Rise Up Time Steppa Mix', 'T...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>reggae</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>6 weeks ago</td>\n",
       "      <td>new</td>\n",
       "      <td>https://chinamanyard.bandcamp.com/album/jailho...</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>Jailhouse Skankin</td>\n",
       "      <td>Stinging Ray &amp; Roots Radics</td>\n",
       "      <td>China</td>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>[reggae, roots, dancehall, one drop, ragga, ro...</td>\n",
       "      <td>[{'Track Title': 'Jailhouse Skankin', 'Track L...</td>\n",
       "      <td>\\n«Mi say chatta box dont come fool me\\nIt's a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5615</th>\n",
       "      <td>reggae</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>6 weeks ago</td>\n",
       "      <td>new</td>\n",
       "      <td>https://throneshaker.bandcamp.com/album/the-cu...</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>The Cure For Dance</td>\n",
       "      <td>RND_ADV_X</td>\n",
       "      <td>Seattle, Washington</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>[reggae, dancehall, dub, electro, roots, ska, ...</td>\n",
       "      <td>[{'Track Title': 'The Cure For Dance', 'Track ...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5616 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Release Genre Release Sub-Genre Search Format  Search Week  \\\n",
       "0              all               all           all    this week   \n",
       "1              all               all           all    this week   \n",
       "2              all               all           all    this week   \n",
       "3              all               all           all    this week   \n",
       "4              all               all           all    this week   \n",
       "...            ...               ...           ...          ...   \n",
       "5611        reggae               all           all  6 weeks ago   \n",
       "5612        reggae               all           all  6 weeks ago   \n",
       "5613        reggae               all           all  6 weeks ago   \n",
       "5614        reggae               all           all  6 weeks ago   \n",
       "5615        reggae               all           all  6 weeks ago   \n",
       "\n",
       "     Search Category                                        Release URL  \\\n",
       "0                top  https://parquetcourts.bandcamp.com/album/sympa...   \n",
       "1                top  https://portrayalofguilt.bandcamp.com/album/po...   \n",
       "2                top  https://johncarpentermusic.bandcamp.com/album/...   \n",
       "3                top  https://tossportal.bandcamp.com/album/still-sl...   \n",
       "4                top  https://grouchnz.bandcamp.com/album/rare-speci...   \n",
       "...              ...                                                ...   \n",
       "5611             new       https://wildmanriddim.bandcamp.com/album/s-t   \n",
       "5612             new  https://basscultureplayers.bandcamp.com/album/...   \n",
       "5613             new   https://rastenda.bandcamp.com/album/rise-up-time   \n",
       "5614             new  https://chinamanyard.bandcamp.com/album/jailho...   \n",
       "5615             new  https://throneshaker.bandcamp.com/album/the-cu...   \n",
       "\n",
       "     Scrape Date                         Release Title  \\\n",
       "0     2021-08-19                     Sympathy for Life   \n",
       "1     2021-08-19  portrayal of guilt / Chat Pile Split   \n",
       "2     2021-08-19                   Halloween Kills OST   \n",
       "3     2021-08-19                 still slipping vol. 1   \n",
       "4     2021-08-19                        Rare Specimens   \n",
       "...          ...                                   ...   \n",
       "5611  2021-08-20                                   S/T   \n",
       "5612  2021-08-20                          War Refugees   \n",
       "5613  2021-08-20                          Rise Up Time   \n",
       "5614  2021-08-20                     Jailhouse Skankin   \n",
       "5615  2021-08-20                    The Cure For Dance   \n",
       "\n",
       "                          Artist Name          Artist Location Release Date  \\\n",
       "0                      Parquet Courts       Brooklyn, New York   2021-10-22   \n",
       "1                  portrayal of guilt            Austin, Texas   2021-08-17   \n",
       "2                      John Carpenter  Los Angeles, California   2021-10-15   \n",
       "3                         Joy Orbison               London, UK   2021-08-13   \n",
       "4              Grouch / Grouch In Dub              New Zealand   2021-08-16   \n",
       "...                               ...                      ...          ...   \n",
       "5611                  Wild Man Riddim             Oslo, Norway   2015-12-31   \n",
       "5612  Old John / Bass Culture Players            Madrid, Spain   2021-07-05   \n",
       "5613       Ras Tenda /Sister Defender                       UK   2021-07-04   \n",
       "5614      Stinging Ray & Roots Radics                    China   2021-07-02   \n",
       "5615                        RND_ADV_X      Seattle, Washington   2021-07-01   \n",
       "\n",
       "                                                   Tags  \\\n",
       "0                   [alternative, indie rock, New York]   \n",
       "1     [punk, black metal, hardcore, metal, post-hard...   \n",
       "2     [alternative, electronic, new age, prog-rock, ...   \n",
       "3                                  [electronic, London]   \n",
       "4     [dub, electronic, grouch, psychedelic, techo, ...   \n",
       "...                                                 ...   \n",
       "5611  [afrobeat, reggae, jazz, ska, skajazz, world, ...   \n",
       "5612  [reggae, athens, bass culture players, dub, ma...   \n",
       "5613  [reggae, roots & culture, roots and culture, U...   \n",
       "5614  [reggae, roots, dancehall, one drop, ragga, ro...   \n",
       "5615  [reggae, dancehall, dub, electro, roots, ska, ...   \n",
       "\n",
       "                                             Track Info  \\\n",
       "0     [{'Track Title': 'Walking at a Downtown Pace',...   \n",
       "1     [{'Track Title': 'Touched by an Angel', 'Track...   \n",
       "2     [{'Track Title': 'Logos Kill', 'Track Lyrics':...   \n",
       "3     [{'Track Title': 'w/ dad & frankie', 'Track Ly...   \n",
       "4     [{'Track Title': 'Right Lymph Node', 'Track Ly...   \n",
       "...                                                 ...   \n",
       "5611  [{'Track Title': 'Breskus Rex', 'Track Lyrics'...   \n",
       "5612  [{'Track Title': 'War Refugees', 'Track Lyrics...   \n",
       "5613  [{'Track Title': 'Rise Up Time Steppa Mix', 'T...   \n",
       "5614  [{'Track Title': 'Jailhouse Skankin', 'Track L...   \n",
       "5615  [{'Track Title': 'The Cure For Dance', 'Track ...   \n",
       "\n",
       "                                             All Lyrics  Number of Tracks  \n",
       "0                                                   N/A                11  \n",
       "1     \\nMy mind, tortured and depraved.\\nDissolving....                 2  \n",
       "2                                                   N/A                20  \n",
       "3                                                   N/A                14  \n",
       "4                                                   N/A                 8  \n",
       "...                                                 ...               ...  \n",
       "5611                                                N/A                 7  \n",
       "5612                                                N/A                 2  \n",
       "5613                                                N/A                 4  \n",
       "5614  \\n«Mi say chatta box dont come fool me\\nIt's a...                 2  \n",
       "5615                                                N/A                12  \n",
       "\n",
       "[5616 rows x 15 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Dataframe\n",
    "scrape_df = pd.DataFrame(scrape_data)\n",
    "scrape_df = scrape_df.drop_duplicates(subset = [\"Release URL\"])\n",
    "\n",
    "scrape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to CSV\n",
    "\n",
    "timestamp = time.strftime('%b-%d-%Y_%H%M%S')\n",
    "scrape_df.to_csv('scrape_data_' + timestamp + '.csv',encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save collected URLS (to be loaded for next batch)\n",
    "with open(\"all_URLS_collected.txt\", \"w\") as fp:\n",
    "    json.dump(all_URLS_collected, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
