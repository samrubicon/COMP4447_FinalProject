{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bsoup\n",
    "import urllib.robotparser\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "import time\n",
    "import dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current firefox version is 1 cannot be loaded. \n",
      "Get LATEST driver version for 1 cannot be loaded. \n",
      "Driver [C:\\Users\\Sam\\.wdm\\drivers\\geckodriver\\win64\\v0.29.1\\geckodriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# Import GeckoDriverManager module.\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "# Install the GeckoDriverManager to run FireFox web browser.\n",
    "driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandcamp Web Scraper Data format information\n",
    "\n",
    "'''\n",
    "\n",
    "scrape_data = pd.DataFrame(columns=['Release Title', \n",
    "                                    'Artist Name', \n",
    "                                    'Artist Location',\n",
    "                                    'Release Date',\n",
    "                                    'Release URL',\n",
    "                                    'Release Genre',\n",
    "                                    'Release Sub-Genre',\n",
    "                                    'Number of Tracks'\n",
    "                                    'Track Info',\n",
    "                                    'Number of Fans',\n",
    "                                    'Tags'])\n",
    "                                    \n",
    "### dictionary entry for track listing\n",
    "\n",
    "track_info_entry = {\n",
    "    'Track Title' : '',\n",
    "    'Track Lyrics' : '',\n",
    "    'Track Number' : '',\n",
    "    'Track Duration': ''\n",
    "}\n",
    "                                    \n",
    "'''\n",
    "\n",
    "# scrape dataframe list to collect release entries\n",
    "scrape_data = []\n",
    "\n",
    "# all URLS collected so far (don't collect duplicate albums for multiple searches)\n",
    "all_URLS_collected = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape bandcamp release page function\n",
    "def scrape_release_page(URL,entry,output=False):\n",
    "    \n",
    "    entry = entry.copy()\n",
    "    \n",
    "    entry['Release URL'] = URL\n",
    "    \n",
    "    # don't add entry if it already exists in scrape dataframe\n",
    "    if URL in all_URLS_collected:\n",
    "        return\n",
    "    \n",
    "    if output==True:\n",
    "        print('retrieving info for ' + URL + ' ...')\n",
    "\n",
    "    headers = {'user-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(URL,headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "\n",
    "        soup = bsoup(response.text, 'lxml')\n",
    "        \n",
    "        # Get title and artist name\n",
    "        title = soup.find('meta',{'name':'title'})['content'].split(', by ')\n",
    "        entry['Release Title'] = title[0]\n",
    "        entry['Artist Name'] = title[1]\n",
    "        \n",
    "        # Get artist location\n",
    "        entry['Artist Location'] = soup.find('span',{'class':'location secondaryText'}).string\n",
    "        \n",
    "        # Get release date\n",
    "        release_date = soup.find('div',{'class':'tralbumData tralbum-credits'}).contents[0].string.strip('\"').strip(' ').replace('releases','').replace('released','')\n",
    "        release_date = dateparser.parse(release_date)\n",
    "        entry['Release Date'] = release_date\n",
    "        \n",
    "        # Get tags\n",
    "        tags = soup.find_all('a',{'class':'tag'})\n",
    "        tags_list = []\n",
    "        for tag in tags:\n",
    "            tags_list.append(tag.string)\n",
    "        entry['Tags'] = tags_list\n",
    "        \n",
    "        # If no genre in entry, leave blank\n",
    "        if 'Release Genre' not in entry:\n",
    "            entry['Release Genre'] = 'N/A'\n",
    "            \n",
    "        # If no subgenre in entry, leave blank\n",
    "        if 'Release Sub-Genre' not in entry:\n",
    "            entry['Release Sub-Genre'] = 'N/A'            \n",
    "        \n",
    "        # Get track information\n",
    "        entry['Track Info'] = []\n",
    "        #tracks = soup.find('table',{'id':'track_table'}).findChildren('tr', recursive=False)\n",
    "        tracks = soup.find('table',{'id':'track_table'}).find_all('tr',{'class':'track_row_view'})\n",
    "        \n",
    "        for track in tracks:\n",
    "            # Track number\n",
    "            track_num = int(track.find('td',{'class':'track-number-col'}).div.string.strip('.'))\n",
    "\n",
    "            # Track title\n",
    "            track_title = track.find('span',{'class':'track-title'})\n",
    "            if track_title:\n",
    "                track_title = track_title.string\n",
    "            else:\n",
    "                track_title = track.find('div',{'class':'title'}).span.string\n",
    "        \n",
    "            # Track duration\n",
    "            track_duration = track.find('span',{'class':'time secondaryText'})\n",
    "            if track_duration:\n",
    "                track_duration = track_duration.string.replace('\\n','').strip(' ')\n",
    "            else:\n",
    "                track_duration = 'N/A'  \n",
    "                \n",
    "            # Track lyrics\n",
    "            track_lyrics = 'N/A'\n",
    "            track_lyric_link = track.find('div',{'class':'info_link'}).a['href']            \n",
    "            if track_lyric_link and '#lyrics' in track_lyric_link:\n",
    "                lyric_tag = track.findNext('tr',{'class':'lyricsRow'})\n",
    "                track_lyrics = lyric_tag.find('td',{'colspan':'4'}).div.string.strip('\"').replace('\\r\\n','\\n')            \n",
    "            \n",
    "            # Add track object to tracks list\n",
    "            track_obj = {'Track Title': track_title, 'Track Lyrics': track_lyrics,\n",
    "                        'Track Number': track_num, 'Track Duration': track_duration}\n",
    "            entry['Track Info'].append(track_obj)\n",
    "\n",
    "        # Number of Tracks\n",
    "        entry['Number of Tracks'] = len(entry['Track Info'])\n",
    "        \n",
    "        # Popularity Index\n",
    "        entry['Number of Fans'] = 'N/A'\n",
    "        driver.get(URL)\n",
    "        foundAllFans = False\n",
    "        fan_pages_searched = 0\n",
    "        while foundAllFans == False and fan_pages_searched < MAX_FAN_PAGES:\n",
    "            try:\n",
    "                more_thumbs = driver.find_element_by_xpath('//a[@class=\"more-thumbs\"]')\n",
    "                fan_pages_searched += 1\n",
    "                if 'display: none' in more_thumbs.get_attribute(\"style\"):\n",
    "                    foundAllFans = True\n",
    "            except:\n",
    "                foundAllFans = True\n",
    "        \n",
    "        if fan_pages_searched == MAX_FAN_PAGES:\n",
    "            entry['Number of Fans'] = '>' + str(MAX_FANS)\n",
    "        else:\n",
    "            try:\n",
    "                parentElement = driver.find_element_by_xpath('//div[@class=\"no-writing\"]')\n",
    "                elementList = parentElement.find_elements_by_tag_name(\"a\")\n",
    "                entry['Number of Fans'] = len(elementList)                   \n",
    "            except:\n",
    "                entry['Number of Fans'] = 0\n",
    "                \n",
    "        if output == True:\n",
    "            pprint(entry)\n",
    "            print()\n",
    "        \n",
    "        # add entry to scrape data\n",
    "        scrape_data.append(entry)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape search page function\n",
    "# scrape the number of pages in the given search URL\n",
    "def scrape_search_page(URL,num_pages=NUM_PAGES,output=False):\n",
    "\n",
    "    # read parameters from link\n",
    "    parameters = URL.split('?')[1:][0].split('&')\n",
    "    genre = 'all'\n",
    "    search_category = 'top'\n",
    "    location = '0'\n",
    "    formatt = 'all'\n",
    "    subgenre = 'all'\n",
    "    weeks = ''\n",
    "    for parameter in parameters:\n",
    "        p = parameter.split('=')\n",
    "        if p[0] == 'g':\n",
    "            genre = p[1]\n",
    "        if p[0] == 's':\n",
    "            search_category = p[1]\n",
    "        if p[0] == 'gn':\n",
    "            location = p[1]\n",
    "        if p[0] == 'f':\n",
    "            formatt = p[1]\n",
    "        if p[0] == 't':\n",
    "            subgenre = p[1]\n",
    "        if p[0] == 'w':\n",
    "            weeks = p[1]\n",
    "    \n",
    "    entry = {'Release Genre': genre,\n",
    "            'Release Sub-Genre': subgenre}\n",
    "    \n",
    "    driver.get(URL)\n",
    "    time.sleep(INITIAL_SEARCH_WAIT)\n",
    "    \n",
    "    # extract URLs from link tags\n",
    "    release_URLS = []\n",
    "    \n",
    "    for i in range(num_pages):\n",
    "        # this is just to ensure that the page is loaded\n",
    "        \n",
    "        html = driver.page_source\n",
    "\n",
    "        # create bsoup object\n",
    "        soup = bsoup(str(html), 'lxml')\n",
    "\n",
    "        # find album link tags on this page\n",
    "        link_tags = soup.find_all('a', {'class':'item-title'})\n",
    "    \n",
    "        for tag in link_tags:\n",
    "            tag_url = tag['href'].split('?')[0]\n",
    "            if tag_url not in release_URLS and tag_url not in all_URLS_collected:\n",
    "                release_URLS.append(tag_url)\n",
    "                all_URLS_collected.append(tag_url)\n",
    "            \n",
    "        #driver.find_element_by_xpath('//a[@class=\"more-thumbs\"]')\n",
    "        driver.find_element_by_xpath(\"//a[contains(text(), 'next')]\").click()\n",
    "\n",
    "    if output == True:\n",
    "        pprint(release_URLS)\n",
    "\n",
    "    for release_URL in release_URLS:\n",
    "        scrape_release_page(release_URL,entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### USER INPUTS ######################################################\n",
    "\n",
    "# list of genres to scrape\n",
    "GENRES = ['all']\n",
    "\n",
    "# scrape for subgenres within genres?\n",
    "SCRAPE_SUBGENRES = False\n",
    "\n",
    "# dictionary of subgenres to scrape, if scrape_subgenres = True\n",
    "SUBGENRES = {\n",
    "                'rock': ['indie','prog-rock','post-rock','rock-roll','psychedelic-rock'],\n",
    "                'metal': [],\n",
    "                'alternative': [],\n",
    "                'hip-hop-rap': [],\n",
    "                'experimental': [],\n",
    "                'punk': [],\n",
    "                'folk': [],\n",
    "                'pop': [],\n",
    "                'acoustic': [],\n",
    "                'funk': [],\n",
    "                'country': [],\n",
    "                'blues': []\n",
    "            }\n",
    "\n",
    "# list of search categories to scrape ['top', 'new', 'rec']\n",
    "#   top = best-selling\n",
    "#   new = new arrivals\n",
    "#   rec = artist-recommended\n",
    "SEARCH_CATEGORIES = ['top']\n",
    "\n",
    "# list of locations to scrape\n",
    "# location = 0 returns search results for all locations\n",
    "LOCATIONS = [0] \n",
    "\n",
    "# list of formats to scrape ['all','digital','vinyl','cd','cassette']\n",
    "FORMATS = ['all']\n",
    "\n",
    "# list of weeks to scrape\n",
    "# valid weeks: [-1,0,678,677,676,675,674,673]\n",
    "# today, this week, last week, 2, 3, 4, 5, 6 weeks ago\n",
    "# NOT IMPLEMENTED!\n",
    "# weeks = []\n",
    "\n",
    "# number of pages to scrape (10 produces 40-100 results)\n",
    "NUM_PAGES = 10 \n",
    "\n",
    "# Initial time to wait for Bandcamp Discover page to load\n",
    "INITIAL_SEARCH_WAIT = 5\n",
    "\n",
    "# retrieve no more than this many fans for popularity index\n",
    "MAX_FANS = 1000\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "# max number of pages of fan results to scrape before hitting MAX_FANS\n",
    "MAX_FAN_PAGES = int(MAX_FANS / 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping top all albums from 0 in all format...\n",
      "['https://portrayalofguilt.bandcamp.com/album/portrayal-of-guilt-chat-pile-split',\n",
      " 'https://johncarpentermusic.bandcamp.com/album/halloween-kills-ost',\n",
      " 'https://tossportal.bandcamp.com/album/still-slipping-vol-1',\n",
      " 'https://chatpile.bandcamp.com/album/portrayal-of-guilt-chat-pile-split',\n",
      " 'https://cherubs.bandcamp.com/album/slo-blo-4-frnz-sxy',\n",
      " 'https://boniver.bandcamp.com/album/bon-iver-10th-anniversary-edition',\n",
      " 'https://newretrowave.bandcamp.com/album/love-kills-the-demon',\n",
      " 'https://creepingdeathtx.bandcamp.com/album/the-edge-of-existence',\n",
      " 'https://orangemilkrecords.bandcamp.com/album/wlfgrl-vinyl',\n",
      " 'https://notmeanttohappen.bandcamp.com/album/the-rising-and-setting-of-the-heavenly-bodies',\n",
      " 'https://cuedotrecords.bandcamp.com/album/ash-dome',\n",
      " 'https://projektrecords.bandcamp.com/album/kitsune-name-your-price',\n",
      " 'https://lisabelladonna.bandcamp.com/album/moogmentum-presented-by-the-bob-moog-foundation',\n",
      " 'https://grouchnz.bandcamp.com/album/rare-specimens',\n",
      " 'https://theweatherstation.bandcamp.com/album/all-of-it-was-mine-2',\n",
      " 'https://hausumountain.bandcamp.com/album/ultra-cycle-pt-3-autumnal-age',\n",
      " 'https://wednesdayband.bandcamp.com/album/twin-plagues-2',\n",
      " 'https://pakt-moonjune.bandcamp.com/album/pakt-live-in-kennett-square',\n",
      " 'https://circuitdesyeux.bandcamp.com/album/io',\n",
      " 'https://2mellomakes.bandcamp.com/album/sounds-of-tokyo-to-future',\n",
      " 'https://linguaignota.bandcamp.com/album/sinner-get-ready',\n",
      " 'https://militariegun.bandcamp.com/album/all-roads-lead-to-the-gun-ii',\n",
      " 'https://archspire.bandcamp.com/album/bleed-the-future',\n",
      " 'https://wildfiresgreece.bandcamp.com/album/urgent-support-for-the-fire-stricken-areas-in-greece-compilation',\n",
      " 'https://mpsvinyl.com/album/what-have-you-done-dark-secrets',\n",
      " 'https://listen.20buckspin.com/album/deconsecrate',\n",
      " 'https://quicksandnyc.bandcamp.com/album/distant-populations',\n",
      " 'https://lostarmor.bandcamp.com/album/long-quests-and-dull-blades',\n",
      " 'https://kalax.bandcamp.com/album/never-let-you-go',\n",
      " 'https://filmjunk.bandcamp.com/album/neill-blomkamp',\n",
      " 'https://saultglobal.bandcamp.com/album/nine',\n",
      " 'https://godisinthetvzine.bandcamp.com/album/a-carnival-of-sorts-an-r-e-m-covers-compilation',\n",
      " 'https://pjbridger.bandcamp.com/album/pj-bridger-pj-dubs-02',\n",
      " 'https://grouchnz.bandcamp.com/album/future-relic',\n",
      " 'https://tomcardy.bandcamp.com/album/artificial-intelligence',\n",
      " 'https://lavenue.bandcamp.com/album/azure',\n",
      " 'https://neurosis.bandcamp.com/album/official-bootleg-01-live-in-lyon-france-110299',\n",
      " 'https://regainrecords.bandcamp.com/album/i-am-the-void',\n",
      " 'https://everytimeidie.bandcamp.com/album/radical',\n",
      " 'https://cheersquadrecordstapes.bandcamp.com/album/im-sorry-sir-that-riff-s-been-taken',\n",
      " 'https://music.businesscasual.biz/album/emotion-engine',\n",
      " 'https://gatecreeper.bandcamp.com/album/an-unexpected-reality',\n",
      " 'https://sullyuk.bandcamp.com/album/5ives-sliding',\n",
      " 'https://clozee.bandcamp.com/album/nouvelle-era',\n",
      " 'https://bigthief.bandcamp.com/album/little-things-sparrow',\n",
      " 'https://pinknavel.bandcamp.com/album/epic',\n",
      " 'https://diskordband.bandcamp.com/album/degenerations-dissonant-technical-death-metal',\n",
      " 'https://moatun7.bandcamp.com/album/moa090',\n",
      " 'https://kiyadama.bandcamp.com/album/vessel',\n",
      " 'https://iamladyblackbird.bandcamp.com/album/black-acid-soul',\n",
      " 'https://rawppl.bandcamp.com/album/raw-summer-hits-ii-special-edits',\n",
      " 'https://axiomverge.bandcamp.com/album/axiom-verge-2-soundtrack',\n",
      " 'https://roundwavecrusher.bandcamp.com/album/super-tek-type-specimen-01',\n",
      " 'https://music.bye2.co.uk/album/teeth-restoration',\n",
      " 'https://altingunband.bandcamp.com/album/lem',\n",
      " 'https://thecaretaker.bandcamp.com/album/everywhere-at-the-end-of-time',\n",
      " 'https://alchemyofflesh.bandcamp.com/album/ageless-abominations',\n",
      " 'https://kingdude.bandcamp.com/album/beware-of-darkness',\n",
      " 'https://magdalenabay.bandcamp.com/album/mercurial-world',\n",
      " 'https://nugenea.bandcamp.com/album/marechi-with-c-lia-kameni',\n",
      " 'https://stevehartlett.bandcamp.com/album/308',\n",
      " 'https://taraka1111.bandcamp.com/album/welcome-to-paradise-lost',\n",
      " 'https://deafheavens.bandcamp.com/album/infinite-granite',\n",
      " 'https://0101.bandcamp.com/album/p-tisserie-snail',\n",
      " 'https://selbalamir.bandcamp.com/album/swell',\n",
      " 'https://tysegall.bandcamp.com/album/harmonizer',\n",
      " 'https://crass.bandcamp.com/album/christ-alive-the-rehearsal',\n",
      " 'https://tanyamorgan.bandcamp.com/album/don-and-von',\n",
      " 'https://meandcassity.bandcamp.com/album/covers-four',\n",
      " 'https://toytonics.bandcamp.com/album/italomania',\n",
      " 'https://alixperez.bandcamp.com/album/burning-babylon-empty-words',\n",
      " 'https://iamjengi.bandcamp.com/album/berlin-trauma-ep',\n",
      " 'https://spermchurch.bandcamp.com/album/merdeka-atau-mati',\n",
      " 'https://darkentriesrecords.bandcamp.com/album/deux-filles-silence-wisdom-double-happiness',\n",
      " 'https://jaru.bandcamp.com/album/painful-enlightenment',\n",
      " 'https://vinterkrig.bandcamp.com/album/h-rskare-ver-stj-rnorna-och-mina-dr-mmar-mc-2021',\n",
      " 'https://chamberofunlight.bandcamp.com/album/realm-of-the-night',\n",
      " 'https://deltasleep.bandcamp.com/album/management',\n",
      " 'https://mariawhorn.bandcamp.com/album/stigsj-kyrka-organ-rehearsal-tape',\n",
      " 'https://floatingpoints.bandcamp.com/album/promises']\n"
     ]
    }
   ],
   "source": [
    "# main web scraper loop\n",
    "\n",
    "for genre in GENRES:\n",
    "    for category in SEARCH_CATEGORIES:\n",
    "        for location in LOCATIONS:\n",
    "            for formatt in FORMATS:\n",
    "                    \n",
    "                scrape_URL = 'https://bandcamp.com/?g=' + genre + '&s=' + category + '&p=0' + '&gn=' + str(location) + '&f=' + formatt\n",
    "                print('scraping ' + category + ' ' + genre + ' albums from ' + str(location) + ' in ' + formatt + ' format...')\n",
    "                scrape_search_page(scrape_URL)\n",
    "                    \n",
    "                if SCRAPE_SUBGENRES and genre in SUBGENRES:\n",
    "                    for subgenre in SUBGENRES[genre]:\n",
    "                        print('scraping ' + category + ' ' + genre + ' (' + subgenre + ') albums from ' + str(location) + ' in ' + formatt + ' format...')\n",
    "                        subgenre_scrape_URL = scrape_URL + '&t=' + subgenre\n",
    "                        scrape_search_page(subgenre_scrape_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOHN KING CAVE scrapes\n",
    "\n",
    "scrape_release_page('https://johnkingcave.bandcamp.com/album/devil-rides-beside',{'Release Genre':'folk'})\n",
    "scrape_release_page('https://johnkingcave.bandcamp.com/album/oh-my-love',{'Release Genre':'folk'})\n",
    "scrape_release_page('https://johnkingcave.bandcamp.com/album/emotion-tread-light',{'Release Genre':'folk'})\n",
    "scrape_release_page('https://johnkingcave.bandcamp.com/album/720-split',{'Release Genre':'folk'})\n",
    "scrape_release_page('https://johnkingcave.bandcamp.com/album/sing-a-song',{'Release Genre':'folk'})\n",
    "\n",
    "# Bug: Doesn't work for tracks\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/track/i-love-america',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/track/shes-coming-down-the-line-2',{'Release Genre':'folk'})\n",
    "#scrape_release_page('https://johnkingcave.bandcamp.com/track/labyrinth-of-faith',{'Release Genre':'folk'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Genre</th>\n",
       "      <th>Release URL</th>\n",
       "      <th>Number of Tracks</th>\n",
       "      <th>Release Title</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Artist Location</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Release Sub-Genre</th>\n",
       "      <th>Track Info</th>\n",
       "      <th>Number of Fans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>folk</td>\n",
       "      <td>https://johnkingcave.bandcamp.com/album/devil-...</td>\n",
       "      <td>12</td>\n",
       "      <td>Devil Rides Beside</td>\n",
       "      <td>John King Cave</td>\n",
       "      <td>Albuquerque, New Mexico</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>[folk, alt-country, alternative, americana, el...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[{'Track Title': 'Half Moon', 'Track Lyrics': ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>folk</td>\n",
       "      <td>https://johnkingcave.bandcamp.com/album/oh-my-...</td>\n",
       "      <td>30</td>\n",
       "      <td>Oh My Love</td>\n",
       "      <td>John King Cave</td>\n",
       "      <td>Albuquerque, New Mexico</td>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>[folk, alt-country, country, country western, ...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[{'Track Title': 'Oh My Love (Theme)', 'Track ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>folk</td>\n",
       "      <td>https://johnkingcave.bandcamp.com/album/emotio...</td>\n",
       "      <td>3</td>\n",
       "      <td>Emotion / Tread Light</td>\n",
       "      <td>John King Cave</td>\n",
       "      <td>Albuquerque, New Mexico</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>[folk, alternative, electronica, indie, pop, A...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[{'Track Title': 'Emotion', 'Track Lyrics': 'E...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>folk</td>\n",
       "      <td>https://johnkingcave.bandcamp.com/album/720-split</td>\n",
       "      <td>2</td>\n",
       "      <td>720 Split</td>\n",
       "      <td>John King Cave</td>\n",
       "      <td>Albuquerque, New Mexico</td>\n",
       "      <td>2020-06-12</td>\n",
       "      <td>[folk, hip-hop, rap, pop, Albuquerque]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[{'Track Title': 'Gran Torino (feat. Naomi Van...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>folk</td>\n",
       "      <td>https://johnkingcave.bandcamp.com/album/sing-a...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sing a Song</td>\n",
       "      <td>John King Cave</td>\n",
       "      <td>Albuquerque, New Mexico</td>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>[folk, Albuquerque]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[{'Track Title': 'Sing a Song', 'Track Lyrics'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Genre                                        Release URL  \\\n",
       "0          folk  https://johnkingcave.bandcamp.com/album/devil-...   \n",
       "1          folk  https://johnkingcave.bandcamp.com/album/oh-my-...   \n",
       "4          folk  https://johnkingcave.bandcamp.com/album/emotio...   \n",
       "5          folk  https://johnkingcave.bandcamp.com/album/720-split   \n",
       "6          folk  https://johnkingcave.bandcamp.com/album/sing-a...   \n",
       "\n",
       "   Number of Tracks          Release Title     Artist Name  \\\n",
       "0                12     Devil Rides Beside  John King Cave   \n",
       "1                30             Oh My Love  John King Cave   \n",
       "4                 3  Emotion / Tread Light  John King Cave   \n",
       "5                 2              720 Split  John King Cave   \n",
       "6                 1            Sing a Song  John King Cave   \n",
       "\n",
       "           Artist Location Release Date  \\\n",
       "0  Albuquerque, New Mexico   2020-05-01   \n",
       "1  Albuquerque, New Mexico   2020-12-25   \n",
       "4  Albuquerque, New Mexico   2020-01-01   \n",
       "5  Albuquerque, New Mexico   2020-06-12   \n",
       "6  Albuquerque, New Mexico   2020-06-05   \n",
       "\n",
       "                                                Tags Release Sub-Genre  \\\n",
       "0  [folk, alt-country, alternative, americana, el...               N/A   \n",
       "1  [folk, alt-country, country, country western, ...               N/A   \n",
       "4  [folk, alternative, electronica, indie, pop, A...               N/A   \n",
       "5             [folk, hip-hop, rap, pop, Albuquerque]               N/A   \n",
       "6                                [folk, Albuquerque]               N/A   \n",
       "\n",
       "                                          Track Info  Number of Fans  \n",
       "0  [{'Track Title': 'Half Moon', 'Track Lyrics': ...               8  \n",
       "1  [{'Track Title': 'Oh My Love (Theme)', 'Track ...               1  \n",
       "4  [{'Track Title': 'Emotion', 'Track Lyrics': 'E...               0  \n",
       "5  [{'Track Title': 'Gran Torino (feat. Naomi Van...               0  \n",
       "6  [{'Track Title': 'Sing a Song', 'Track Lyrics'...               0  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Dataframe\n",
    "scrape_df = pd.DataFrame(scrape_data)\n",
    "scrape_df = scrape_df.drop_duplicates(subset = [\"Release URL\"])\n",
    "\n",
    "# save dataframe\n",
    "#scrape_df.to_pickle('scrape_data.pkl')\n",
    "\n",
    "scrape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
